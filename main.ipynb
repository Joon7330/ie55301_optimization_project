{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as tvm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64ff192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset of ImageNet val: 1000 samples\n"
     ]
    }
   ],
   "source": [
    "IMAGENET_ROOT = \"/mnt/SafeAILab/datasets/imagenet\"\n",
    "\n",
    "def get_imagenet_val_loader(root, batch_size=64, subset_size=1000):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    full_val = torchvision.datasets.ImageNet(\n",
    "        root=root,\n",
    "        split=\"val\",\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    if subset_size is not None and subset_size < len(full_val):\n",
    "        indices = list(range(subset_size))\n",
    "        val_dataset = Subset(full_val, indices)\n",
    "        print(f\"Using subset of ImageNet val: {subset_size} samples\")\n",
    "    else:\n",
    "        val_dataset = full_val\n",
    "        print(f\"Using full ImageNet val: {len(full_val)} samples\")\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    return val_loader\n",
    "\n",
    "\n",
    "val_loader = get_imagenet_val_loader(IMAGENET_ROOT, batch_size=64, subset_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d9c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded alexnet on cuda\n",
      "Loaded resnet18 on cuda\n",
      "Loaded vgg16_bn on cuda\n",
      "Loaded densenet121 on cuda\n",
      "Loaded mobilenet_v2 on cuda\n"
     ]
    }
   ],
   "source": [
    "def get_imagenet_models(device):\n",
    "    models_dict = {}\n",
    "\n",
    "    models_dict[\"alexnet\"]   = tvm.alexnet(weights=tvm.AlexNet_Weights.IMAGENET1K_V1)\n",
    "    models_dict[\"resnet18\"]  = tvm.resnet18(weights=tvm.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    models_dict[\"vgg16_bn\"]  = tvm.vgg16_bn(weights=tvm.VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "    models_dict[\"densenet121\"] = tvm.densenet121(weights=tvm.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "    models_dict[\"mobilenet_v2\"] = tvm.mobilenet_v2(weights=tvm.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(f\"Loaded {name} on {device}\")\n",
    "\n",
    "    return models_dict\n",
    "\n",
    "models_dict = get_imagenet_models(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c11f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack_vanilla(model, x, y=None, epsilon=2/255, num_steps=10, step_size=1e-2, random_start=True, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "\n",
    "    if y is None:\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            y = logits.argmax(dim=1)\n",
    "    y = y.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if random_start:\n",
    "        delta = torch.empty_like(x).uniform_(-epsilon, epsilon)\n",
    "    else:\n",
    "        delta = torch.zeros_like(x)\n",
    "    delta = delta.to(device)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        delta.requires_grad_(True)\n",
    "\n",
    "        x_adv = torch.clamp(x + delta, 0, 1)\n",
    "        logits = model(x_adv)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        grad = torch.autograd.grad(loss, delta, retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            delta = delta + step_size * grad.sign()\n",
    "            delta.clamp_(-epsilon, epsilon)\n",
    "\n",
    "        delta = delta.detach()\n",
    "\n",
    "    x_adv = torch.clamp(x + delta, 0, 1)\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack_with_optimizer(model, x, y=None, epsilon=2/255, num_steps=10, optimizer_name=\"sgd\", step_size=1e-2, random_start=True, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "\n",
    "    if y is None:\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            y = logits.argmax(dim=1)\n",
    "    y = y.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if random_start:\n",
    "        delta = torch.empty_like(x).uniform_(-epsilon, epsilon)\n",
    "    else:\n",
    "        delta = torch.zeros_like(x)\n",
    "    delta = delta.to(device)\n",
    "    delta.requires_grad_(True)\n",
    "\n",
    "    # optimizer\n",
    "    if optimizer_name.lower() == \"sgd\":\n",
    "        optimizer = optim.SGD([delta], lr=step_size)\n",
    "    elif optimizer_name.lower() == \"momentum\":\n",
    "        optimizer = optim.SGD([delta], lr=step_size, momentum=0.9)\n",
    "    elif optimizer_name.lower() == \"adam\":\n",
    "        optimizer = optim.Adam([delta], lr=step_size)\n",
    "    elif optimizer_name.lower() == \"adamw\":\n",
    "        optimizer = optim.AdamW([delta], lr=step_size)\n",
    "    elif optimizer_name.lower() == \"adamax\":\n",
    "        optimizer = optim.Adamax([delta], lr=step_size)\n",
    "    elif optimizer_name.lower() == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop([delta], lr=step_size, alpha=0.99)\n",
    "    elif optimizer_name.lower() == \"adagrad\":\n",
    "        optimizer = optim.Adagrad([delta], lr=step_size)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        x_adv = torch.clamp(x + delta, 0, 1)\n",
    "\n",
    "        logits = model(x_adv)\n",
    "        ce_loss = loss_fn(logits, y)\n",
    "        attack_loss = -ce_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        attack_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            delta.clamp_(-epsilon, epsilon)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_adv = torch.clamp(x + delta, 0, 1)\n",
    "\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed5fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_attack_strength(\n",
    "    model, dataloader, optimizer_name, step_size,\n",
    "    epsilon, num_steps, device=\"cuda\", max_samples=None\n",
    "):\n",
    "    model.eval()\n",
    "    n = 0\n",
    "\n",
    "    ce_loss_clean_sum = 0.0\n",
    "    ce_loss_adv_sum = 0.0\n",
    "\n",
    "    clean_correct = 0\n",
    "    adv_correct = 0\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    loop = tqdm(dataloader, desc=f\"{optimizer_name.upper()} attack\", leave=False)\n",
    "\n",
    "    for images, labels in loop:\n",
    "        if max_samples is not None and n >= max_samples:\n",
    "            break\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bs = images.size(0)\n",
    "\n",
    "        if max_samples is not None and n + bs > max_samples:\n",
    "            bs = max_samples - n\n",
    "            images = images[:bs]\n",
    "            labels = labels[:bs]\n",
    "        n += bs\n",
    "\n",
    "        # clean\n",
    "        with torch.no_grad():\n",
    "            logits_clean = model(images)\n",
    "            prob_clean = softmax(logits_clean)\n",
    "\n",
    "        ce_loss_clean_sum += loss_fn(logits_clean, labels).item()\n",
    "        pred_clean = logits_clean.argmax(dim=1)\n",
    "        clean_correct += (pred_clean == labels).sum().item()\n",
    "\n",
    "        # adversarial\n",
    "        if optimizer_name == \"vanilla\":\n",
    "            x_adv = pgd_attack_vanilla(\n",
    "                model=model,\n",
    "                x=images,\n",
    "                y=labels,\n",
    "                epsilon=epsilon,\n",
    "                num_steps=num_steps,\n",
    "                step_size=step_size,\n",
    "                device=device,\n",
    "            )\n",
    "        else:\n",
    "            x_adv = pgd_attack_with_optimizer(\n",
    "                model=model,\n",
    "                x=images,\n",
    "                y=labels,\n",
    "                epsilon=epsilon,\n",
    "                num_steps=num_steps,\n",
    "                optimizer_name=optimizer_name,\n",
    "                step_size=step_size,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_adv = model(x_adv)\n",
    "            prob_adv = softmax(logits_adv)\n",
    "\n",
    "        ce_loss_adv_sum += loss_fn(logits_adv, labels).item()\n",
    "        pred_adv = logits_adv.argmax(dim=1)\n",
    "        adv_correct += (pred_adv == labels).sum().item()\n",
    "\n",
    "        loop.set_postfix({\n",
    "            \"clean_acc\": clean_correct / n,\n",
    "            \"robust_acc\": adv_correct / n\n",
    "        })\n",
    "\n",
    "    clean_acc = clean_correct / n\n",
    "    robust_acc = adv_correct / n\n",
    "    asr = 1.0 - robust_acc\n",
    "\n",
    "    return {\n",
    "        \"clean_acc\": clean_acc,\n",
    "        \"robust_acc\": robust_acc,\n",
    "        \"ASR\": asr,\n",
    "        \"n\": n,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a154ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_file(filepath, text):\n",
    "    with open(filepath, \"a\") as f:\n",
    "        f.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4f375db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "max_samples = 1000\n",
    "\n",
    "eps_list = [1/255, 2/255, 3/255, 4/255, 5/255, 6/255, 7/255, 8/255]\n",
    "# steps_list = [5, 10, 15, 20, 25, 30]\n",
    "steps_list = [10]\n",
    "step_factor_list = [1.0]\n",
    "\n",
    "optimizers = [\"vanilla\", \"sgd\", \"momentum\", \"adam\", \"adamw\", \"adamax\", \"rmsprop\", \"adagrad\"]\n",
    "\n",
    "for eps in eps_list:\n",
    "    for T in steps_list:\n",
    "        for factor in step_factor_list:\n",
    "            \n",
    "            step_size = factor * eps / T\n",
    "\n",
    "            log_file = (\n",
    "                f\"results_imagenet_attack_ablation_many_eps_\"\n",
    "                f\"eps{eps:.5f}_steps{T}_factor{factor}.txt\"\n",
    "            )\n",
    "            open(log_file, \"w\").close()\n",
    "            log_to_file(log_file, \"=== ImageNet PGD-Optimizer Attack Ablation Results ===\")\n",
    "\n",
    "            log_to_file(\n",
    "                log_file,\n",
    "                f\"\\n==============================\"\n",
    "                f\"\\n[SETTING] eps={eps:.5f}, steps={T}, factor={factor}, step_size={step_size:.6f}\"\n",
    "                f\"\\n==============================\"\n",
    "            )\n",
    "\n",
    "            for model_name, model in models_dict.items():\n",
    "                if model_name != \"densenet121\":\n",
    "                    continue\n",
    "                log_to_file(log_file, f\"\\n----- Model: {model_name} -----\")\n",
    "\n",
    "                for opt_name in optimizers:\n",
    "                    stats = eval_attack_strength(\n",
    "                        model=model,\n",
    "                        dataloader=val_loader,\n",
    "                        optimizer_name=opt_name,\n",
    "                        step_size=step_size,\n",
    "                        epsilon=eps,\n",
    "                        num_steps=T,\n",
    "                        device=device,\n",
    "                        max_samples=max_samples,\n",
    "                    )\n",
    "\n",
    "                    line = (\n",
    "                        f\"[{opt_name}] \"\n",
    "                        f\"clean_acc={stats['clean_acc']:.4f}, \"\n",
    "                        f\"robust_acc={stats['robust_acc']:.4f}, \"\n",
    "                        f\"ASR={stats['ASR']:.4f}, \"\n",
    "                        f\"samples={stats['n']}\"\n",
    "                    )\n",
    "                    log_to_file(log_file, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
